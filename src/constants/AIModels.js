export const AIModels = [
    // Gemma-2B
    {
      model_id: "gemma-2b-it-q4f16_1-MLC",
      vram_required_MB: 1476.52,
      low_resource_required: false,
      name: "Gemma 2B"
    },
    // Qwen-2
    {
      model_id: "Qwen2-0.5B-Instruct-q0f16-MLC",
      vram_required_MB: 1624.12,
      low_resource_required: true,
      name: "Qwen 2"
    },
    // StableLM-zephyr-1.6B
    {
      model_id: "stablelm-2-zephyr-1.6b-q4f16_1-MLC",
      vram_required_MB: 2454.42,
      low_resource_required: false,
      name: "StableLM"
    },
    // Phi3-mini-instruct
    {
      model_id: "Phi-3-mini-4k-instruct-q4f16_1-MLC",
      vram_required_MB: 3672.07,
      low_resource_required: false,
      name: "Phi 3 mini"
    },
    // Mistral variants
    {
      model_id: "Mistral-7B-Instruct-v0.3-q4f16_1-MLC",
      vram_required_MB: 4573.39,
      low_resource_required: false,
      name: "Mistral"
    },
    // Hermes-2 Pro
    {
      model_id: "Hermes-2-Pro-Llama-3-8B-q4f16_1-MLC",
      vram_required_MB: 4976.13,
      low_resource_required: false,
      name: "Hermes 2 Pro"
    },
    // Llama-3
    {
      model_id: "Llama-3-8B-Instruct-q4f32_1-MLC-1k",
      vram_required_MB: 5295.7,
      low_resource_required: true,
      name: "Llama 3"
    }
  ];
  